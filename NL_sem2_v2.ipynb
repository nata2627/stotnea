{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 1. Мешок слов"
      ],
      "metadata": {
        "id": "xFOX74hlwBsQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su0SBdMPqqQT",
        "outputId": "f166d05f-7bdf-4e97-b727-2c9c90de9704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Словарь уникальных слов: ['a', 'cat', 'is', 'mat', 'on', 'sat', 'the']\n",
            "\n",
            "Частота слов в тексте 1:\n",
            "a: 0\n",
            "cat: 1\n",
            "is: 0\n",
            "mat: 1\n",
            "on: 1\n",
            "sat: 1\n",
            "the: 2\n",
            "\n",
            "Частота слов в тексте 2:\n",
            "a: 1\n",
            "cat: 1\n",
            "is: 1\n",
            "mat: 1\n",
            "on: 1\n",
            "sat: 0\n",
            "the: 1\n",
            "\n",
            "Векторное представление текста 1: [0, 1, 0, 1, 1, 1, 2]\n",
            "Векторное представление текста 2: [1, 1, 1, 1, 1, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "# Исходные тексты\n",
        "text1 = \"The cat sat on the mat.\"\n",
        "text2 = \"A cat is on the mat.\"\n",
        "\n",
        "# Создаем мешки слов (приводим все к нижнему регистру)\n",
        "bow1 = text1.lower().strip('.').split()\n",
        "bow2 = text2.lower().strip('.').split()\n",
        "\n",
        "# Создаем словарь уникальных слов\n",
        "unique_words = sorted(set(bow1 + bow2))\n",
        "print(\"Словарь уникальных слов:\", unique_words)\n",
        "\n",
        "# Расчет частоты слов для каждого текста\n",
        "freq_text1 = {}\n",
        "freq_text2 = {}\n",
        "\n",
        "# Подсчет для текста 1\n",
        "for word in unique_words:\n",
        "    freq_text1[word] = bow1.count(word)\n",
        "\n",
        "# Подсчет для текста 2\n",
        "for word in unique_words:\n",
        "    freq_text2[word] = bow2.count(word)\n",
        "\n",
        "print(\"\\nЧастота слов в тексте 1:\")\n",
        "for word, freq in freq_text1.items():\n",
        "    print(f\"{word}: {freq}\")\n",
        "\n",
        "print(\"\\nЧастота слов в тексте 2:\")\n",
        "for word, freq in freq_text2.items():\n",
        "    print(f\"{word}: {freq}\")\n",
        "\n",
        "# Создаем векторные представления\n",
        "vector1 = [bow1.count(word) for word in unique_words]\n",
        "vector2 = [bow2.count(word) for word in unique_words]\n",
        "\n",
        "print(\"\\nВекторное представление текста 1:\", vector1)\n",
        "print(\"Векторное представление текста 2:\", vector2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 2. Косинусная мера сходства"
      ],
      "metadata": {
        "id": "daqdMNyhw36x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Исходные документы\n",
        "doc1 = \"Data science is the future of technology\"\n",
        "doc2 = \"Technology is evolving with data science\"\n",
        "\n",
        "# Шаг 1: Создаем словарь уникальных слов\n",
        "def create_vocabulary(doc1, doc2):\n",
        "    # Преобразуем тексты в нижний регистр и разбиваем на слова\n",
        "    words1 = doc1.lower().split()\n",
        "    words2 = doc2.lower().split()\n",
        "    # Создаем множество уникальных слов\n",
        "    vocabulary = sorted(set(words1 + words2))\n",
        "    return vocabulary\n",
        "\n",
        "# Шаг 2: Создаем векторы документов\n",
        "def create_vector(doc, vocabulary):\n",
        "    # Считаем частоту слов в документе\n",
        "    word_counts = Counter(doc.lower().split())\n",
        "    # Создаем вектор на основе словаря\n",
        "    vector = [word_counts[word] for word in vocabulary]\n",
        "    return vector\n",
        "\n",
        "# Шаг 3: Вычисляем косинусное сходство\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm1 = np.linalg.norm(vec1)\n",
        "    norm2 = np.linalg.norm(vec2)\n",
        "    return dot_product / (norm1 * norm2)\n",
        "\n",
        "# Создаем словарь\n",
        "vocabulary = create_vocabulary(doc1, doc2)\n",
        "print(\"Словарь:\", vocabulary)\n",
        "\n",
        "# Создаем векторы для документов\n",
        "vector1 = create_vector(doc1, vocabulary)\n",
        "vector2 = create_vector(doc2, vocabulary)\n",
        "print(\"\\nВектор документа 1:\", vector1)\n",
        "print(\"Вектор документа 2:\", vector2)\n",
        "\n",
        "# Вычисляем косинусное сходство\n",
        "similarity = cosine_similarity(vector1, vector2)\n",
        "print(f\"\\nКосинусное сходство: {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un1wjm3wwRXZ",
        "outputId": "6847456f-af38-4843-8634-9aa8b974193b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Словарь: ['data', 'evolving', 'future', 'is', 'of', 'science', 'technology', 'the', 'with']\n",
            "\n",
            "Вектор документа 1: [1, 0, 1, 1, 1, 1, 1, 1, 0]\n",
            "Вектор документа 2: [1, 1, 0, 1, 0, 1, 1, 0, 1]\n",
            "\n",
            "Косинусное сходство: 0.6172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 3. Векторное представление документа"
      ],
      "metadata": {
        "id": "UpvcCaT9xODF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Исходные тексты\n",
        "text1 = \"Artificial intelligence is changing the world\"\n",
        "text2 = \"The world is being shaped by artificial intelligence\"\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Предобработка текста: приведение к нижнему регистру\"\"\"\n",
        "    return text.lower().split()\n",
        "\n",
        "def create_bag_of_words(texts):\n",
        "    \"\"\"Создание мешка слов из списка текстов\"\"\"\n",
        "    # Объединяем все слова и создаем словарь уникальных слов\n",
        "    all_words = []\n",
        "    for text in texts:\n",
        "        all_words.extend(preprocess_text(text))\n",
        "    vocabulary = sorted(set(all_words))\n",
        "\n",
        "    # Создаем словарь с индексами для каждого слова\n",
        "    word_to_index = {word: idx for idx, word in enumerate(vocabulary)}\n",
        "    return vocabulary, word_to_index\n",
        "\n",
        "def create_vector(text, word_to_index):\n",
        "    \"\"\"Создание векторного представления текста\"\"\"\n",
        "    vector = [0] * len(word_to_index)\n",
        "    words = preprocess_text(text)\n",
        "    word_counts = Counter(words)\n",
        "\n",
        "    for word, count in word_counts.items():\n",
        "        if word in word_to_index:\n",
        "            vector[word_to_index[word]] = count\n",
        "    return vector\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"Вычисление косинусного сходства между векторами\"\"\"\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm1 = np.linalg.norm(vec1)\n",
        "    norm2 = np.linalg.norm(vec2)\n",
        "    return dot_product / (norm1 * norm2)\n",
        "\n",
        "# 1. Создаем мешок слов\n",
        "vocabulary, word_to_index = create_bag_of_words([text1, text2])\n",
        "print(\"Мешок слов (словарь):\")\n",
        "for idx, word in enumerate(vocabulary):\n",
        "    print(f\"{idx + 1}. {word}\")\n",
        "\n",
        "# 2. Создаем векторные представления текстов\n",
        "vector1 = create_vector(text1, word_to_index)\n",
        "vector2 = create_vector(text2, word_to_index)\n",
        "\n",
        "print(\"\\nВекторное представление текста 1:\")\n",
        "for word, idx in word_to_index.items():\n",
        "    if vector1[idx] > 0:\n",
        "        print(f\"{word}: {vector1[idx]}\")\n",
        "print(vector1)\n",
        "\n",
        "print(\"\\nВекторное представление текста 2:\")\n",
        "for word, idx in word_to_index.items():\n",
        "    if vector2[idx] > 0:\n",
        "        print(f\"{word}: {vector2[idx]}\")\n",
        "print(vector2)\n",
        "\n",
        "# 3. Вычисляем косинусное сходство\n",
        "similarity = cosine_similarity(vector1, vector2)\n",
        "print(f\"\\nКосинусное сходство между текстами: {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "192-Cl-UxH9e",
        "outputId": "e7ac5f5f-24e4-4d12-a0a3-d8a2b717cfb7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Мешок слов (словарь):\n",
            "1. artificial\n",
            "2. being\n",
            "3. by\n",
            "4. changing\n",
            "5. intelligence\n",
            "6. is\n",
            "7. shaped\n",
            "8. the\n",
            "9. world\n",
            "\n",
            "Векторное представление текста 1:\n",
            "artificial: 1\n",
            "changing: 1\n",
            "intelligence: 1\n",
            "is: 1\n",
            "the: 1\n",
            "world: 1\n",
            "[1, 0, 0, 1, 1, 1, 0, 1, 1]\n",
            "\n",
            "Векторное представление текста 2:\n",
            "artificial: 1\n",
            "being: 1\n",
            "by: 1\n",
            "intelligence: 1\n",
            "is: 1\n",
            "shaped: 1\n",
            "the: 1\n",
            "world: 1\n",
            "[1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
            "\n",
            "Косинусное сходство между текстами: 0.7217\n"
          ]
        }
      ]
    }
  ]
}